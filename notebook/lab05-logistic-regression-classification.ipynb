{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis using sigmoid: tf.div(1., 1 + tf.exp(tf.matmul(X, W) + b))\n",
    "# hypothesis = tf.div(1., 1 + tf.exp(tf.matmul(X, W) + b))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuraty computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "# hypothesis > 0.5: True, False => tf.cast() -> 0 ~ 1사이 값이로 casting함.\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.8720849 [[0.1533487 ]\n",
      " [0.02021614]\n",
      " [0.14707029]\n",
      " [0.0046704 ]\n",
      " [0.00223268]\n",
      " [0.00444721]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 0.5\n",
      "500 0.67360336 [[0.42457178]\n",
      " [0.2884286 ]\n",
      " [0.8745734 ]\n",
      " [0.54859805]\n",
      " [0.67787564]\n",
      " [0.919905  ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "1000 0.60301965 [[0.32511565]\n",
      " [0.23527992]\n",
      " [0.8627129 ]\n",
      " [0.55838144]\n",
      " [0.71935433]\n",
      " [0.9428358 ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "1500 0.54767555 [[0.2690442 ]\n",
      " [0.216552  ]\n",
      " [0.83854586]\n",
      " [0.5714603 ]\n",
      " [0.7454811 ]\n",
      " [0.94953716]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "2000 0.49944556 [[0.23151408]\n",
      " [0.21008462]\n",
      " [0.8070804 ]\n",
      " [0.5857563 ]\n",
      " [0.7652859 ]\n",
      " [0.9515417 ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "2500 0.45662224 [[0.20306584]\n",
      " [0.20833361]\n",
      " [0.7711807 ]\n",
      " [0.6006043 ]\n",
      " [0.7823604 ]\n",
      " [0.9521301 ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "3000 0.41860795 [[0.17973232]\n",
      " [0.20813788]\n",
      " [0.733032  ]\n",
      " [0.61552864]\n",
      " [0.7980275 ]\n",
      " [0.95252144]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "3500 0.3849657 [[0.1597547 ]\n",
      " [0.20808555]\n",
      " [0.6943447 ]\n",
      " [0.6301607 ]\n",
      " [0.812694  ]\n",
      " [0.953179  ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "4000 0.35525528 [[0.14231   ]\n",
      " [0.20758519]\n",
      " [0.65636504]\n",
      " [0.6442442 ]\n",
      " [0.8264282 ]\n",
      " [0.9542269 ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "4500 0.32903054 [[0.12696826]\n",
      " [0.20644857]\n",
      " [0.61991906]\n",
      " [0.65762717]\n",
      " [0.83920705]\n",
      " [0.95563716]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "5000 0.30586067 [[0.1134579 ]\n",
      " [0.20467912]\n",
      " [0.585492  ]\n",
      " [0.6702388 ]\n",
      " [0.8510105 ]\n",
      " [0.95732474]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "5500 0.2853478 [[0.10156904]\n",
      " [0.20236114]\n",
      " [0.5533169 ]\n",
      " [0.6820623 ]\n",
      " [0.8618451 ]\n",
      " [0.95919377]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "6000 0.26713616 [[0.09111758]\n",
      " [0.19960308]\n",
      " [0.52345705]\n",
      " [0.69311506]\n",
      " [0.8717447 ]\n",
      " [0.9611598 ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.8333333\n",
      "6500 0.25091395 [[0.08193681]\n",
      " [0.19651698]\n",
      " [0.49586585]\n",
      " [0.7034375 ]\n",
      " [0.880764  ]\n",
      " [0.9631552 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "7000 0.23641105 [[0.07386986]\n",
      " [0.19319424]\n",
      " [0.4704395 ]\n",
      " [0.7130782 ]\n",
      " [0.88897026]\n",
      " [0.9651326 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "7500 0.22339606 [[0.06677622]\n",
      " [0.18971398]\n",
      " [0.4470329 ]\n",
      " [0.72208685]\n",
      " [0.8964316 ]\n",
      " [0.96705663]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "8000 0.21167164 [[0.06053023]\n",
      " [0.1861409 ]\n",
      " [0.4254905 ]\n",
      " [0.73051596]\n",
      " [0.90321815]\n",
      " [0.9689057 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "8500 0.20106983 [[0.05502085]\n",
      " [0.18252558]\n",
      " [0.40565407]\n",
      " [0.7384147 ]\n",
      " [0.90939593]\n",
      " [0.970666  ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "9000 0.19144775 [[0.05015071]\n",
      " [0.17890644]\n",
      " [0.3873705 ]\n",
      " [0.74582815]\n",
      " [0.9150265 ]\n",
      " [0.9723308 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "9500 0.18268351 [[0.04583546]\n",
      " [0.17531328]\n",
      " [0.3704964 ]\n",
      " [0.75279915]\n",
      " [0.92016643]\n",
      " [0.97389776]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "10000 0.1746731 [[0.04200207]\n",
      " [0.17176783]\n",
      " [0.35489875]\n",
      " [0.7593653 ]\n",
      " [0.92486626]\n",
      " [0.9753677 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 1.0\n",
      "Hypothesis: [[0.04199484]\n",
      " [0.17176078]\n",
      " [0.35486874]\n",
      " [0.7593781 ]\n",
      " [0.9248753 ]\n",
      " [0.9753705 ]] \n",
      "Predicted: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for step in range(10001):\n",
    "    cost_val, h_val, _, p_val, a_val = session.run([cost, hypothesis, train, predicted, accuracy],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(step, cost_val, h_val, p_val, a_val)\n",
    "\n",
    "h_val, p_val, a_val = session.run([hypothesis, predicted, accuracy],\n",
    "                                  feed_dict = {X: x_data, Y: y_data})\n",
    "print(\"Hypothesis:\", h_val, \"\\nPredicted:\", p_val, \"\\nAccuracy:\", a_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
