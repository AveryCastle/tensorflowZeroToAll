{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data set\n",
    "x1_train = [73., 93., 89., 96., 73.]\n",
    "x2_train = [80., 88., 91., 98., 66.]\n",
    "x3_train = [75., 93., 90., 100., 70.]\n",
    "y_train = [152., 185., 180., 196., 142.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "W1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "W2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "W3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis\n",
    "\n",
    "# placeholder 사용 안 할 때\n",
    "# hypothesis = x1_train * W1 + x2_train * W2 + x3_train + b\n",
    "\n",
    "# placeholder 사용 할 때\n",
    "hypothesis = x1 * W1 + x2 * W2 + x3 * W3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare session\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  0.59675705 \n",
      " Prediction:  [152.1481  184.33904 180.95709 195.03615 142.82458]\n",
      "100 Cost:  0.59457284 \n",
      " Prediction:  [152.14731 184.33923 180.95644 195.03885 142.82217]\n",
      "200 Cost:  0.59237945 \n",
      " Prediction:  [152.14651 184.33946 180.95578 195.04158 142.81978]\n",
      "300 Cost:  0.5902136 \n",
      " Prediction:  [152.1457  184.3397  180.95512 195.04428 142.81743]\n",
      "400 Cost:  0.5880339 \n",
      " Prediction:  [152.14484 184.33995 180.95442 195.04695 142.81505]\n",
      "500 Cost:  0.58587843 \n",
      " Prediction:  [152.14401 184.34021 180.95377 195.04967 142.81273]\n",
      "600 Cost:  0.5837517 \n",
      " Prediction:  [152.14317 184.34048 180.95311 195.05232 142.81042]\n",
      "700 Cost:  0.5816201 \n",
      " Prediction:  [152.14229 184.34074 180.95241 195.05496 142.80812]\n",
      "800 Cost:  0.5795009 \n",
      " Prediction:  [152.14142 184.34102 180.95175 195.05765 142.80585]\n",
      "900 Cost:  0.5773936 \n",
      " Prediction:  [152.14053 184.34132 180.95107 195.06029 142.8036 ]\n",
      "1000 Cost:  0.57529175 \n",
      " Prediction:  [152.13963 184.34164 180.9504  195.06294 142.80138]\n",
      "1100 Cost:  0.573203 \n",
      " Prediction:  [152.1387  184.34193 180.94969 195.06554 142.79912]\n",
      "1200 Cost:  0.5711216 \n",
      " Prediction:  [152.1378  184.34225 180.94902 195.06819 142.79692]\n",
      "1300 Cost:  0.5690558 \n",
      " Prediction:  [152.13687 184.34259 180.94833 195.0708  142.79474]\n",
      "1400 Cost:  0.5670106 \n",
      " Prediction:  [152.13593 184.34293 180.94765 195.07338 142.79257]\n",
      "1500 Cost:  0.56495744 \n",
      " Prediction:  [152.13496 184.34325 180.94695 195.07597 142.79039]\n",
      "1600 Cost:  0.5629072 \n",
      " Prediction:  [152.13402 184.34361 180.94626 195.0786  142.78825]\n",
      "1700 Cost:  0.56089324 \n",
      " Prediction:  [152.13306 184.34398 180.94556 195.08115 142.78615]\n",
      "1800 Cost:  0.55887544 \n",
      " Prediction:  [152.13206 184.34431 180.94485 195.08371 142.78401]\n",
      "1900 Cost:  0.55687 \n",
      " Prediction:  [152.13109 184.34467 180.94415 195.08626 142.78189]\n",
      "2000 Cost:  0.55487597 \n",
      " Prediction:  [152.1301  184.34505 180.94347 195.0888  142.7798 ]\n",
      "2100 Cost:  0.5528962 \n",
      " Prediction:  [152.12909 184.34544 180.94276 195.09134 142.77776]\n",
      "2200 Cost:  0.5509189 \n",
      " Prediction:  [152.12808 184.34581 180.94205 195.09387 142.7757 ]\n",
      "2300 Cost:  0.5489474 \n",
      " Prediction:  [152.12708 184.34619 180.94135 195.09642 142.77365]\n",
      "2400 Cost:  0.5469983 \n",
      " Prediction:  [152.12605 184.3466  180.94066 195.09894 142.77164]\n",
      "2500 Cost:  0.54505193 \n",
      " Prediction:  [152.12502 184.347   180.93994 195.10143 142.7696 ]\n",
      "2600 Cost:  0.54310405 \n",
      " Prediction:  [152.12398 184.3474  180.93921 195.10393 142.7676 ]\n",
      "2700 Cost:  0.54117787 \n",
      " Prediction:  [152.12294 184.3478  180.9385  195.10641 142.76558]\n",
      "2800 Cost:  0.53927284 \n",
      " Prediction:  [152.12192 184.3482  180.93782 195.1089  142.76361]\n",
      "2900 Cost:  0.5373567 \n",
      " Prediction:  [152.12086 184.34865 180.93712 195.1114  142.76166]\n",
      "3000 Cost:  0.5354573 \n",
      " Prediction:  [152.1198  184.34904 180.93639 195.11385 142.75967]\n",
      "3100 Cost:  0.533574 \n",
      " Prediction:  [152.11874 184.34946 180.93568 195.11632 142.75774]\n",
      "3200 Cost:  0.5316824 \n",
      " Prediction:  [152.11769 184.3499  180.93497 195.11877 142.75578]\n",
      "3300 Cost:  0.52981365 \n",
      " Prediction:  [152.11661 184.35034 180.93427 195.12123 142.75388]\n",
      "3400 Cost:  0.5279614 \n",
      " Prediction:  [152.11554 184.3508  180.93356 195.12366 142.75198]\n",
      "3500 Cost:  0.52610433 \n",
      " Prediction:  [152.11446 184.35121 180.93283 195.12608 142.75006]\n",
      "3600 Cost:  0.5242606 \n",
      " Prediction:  [152.1134  184.35165 180.93213 195.12852 142.74817]\n",
      "3700 Cost:  0.5224245 \n",
      " Prediction:  [152.11229 184.35211 180.9314  195.1309  142.74628]\n",
      "3800 Cost:  0.52060276 \n",
      " Prediction:  [152.11118 184.35257 180.9307  195.13332 142.74442]\n",
      "3900 Cost:  0.5187794 \n",
      " Prediction:  [152.11008 184.35303 180.92996 195.13573 142.74257]\n",
      "4000 Cost:  0.51697385 \n",
      " Prediction:  [152.10901 184.35349 180.92926 195.13812 142.7407 ]\n",
      "4100 Cost:  0.51517993 \n",
      " Prediction:  [152.10791 184.35393 180.92856 195.14052 142.73886]\n",
      "4200 Cost:  0.51338655 \n",
      " Prediction:  [152.10681 184.3544  180.92784 195.1429  142.73703]\n",
      "4300 Cost:  0.5116008 \n",
      " Prediction:  [152.10568 184.35487 180.92712 195.14528 142.73521]\n",
      "4400 Cost:  0.50984 \n",
      " Prediction:  [152.10458 184.35535 180.9264  195.14763 142.73343]\n",
      "4500 Cost:  0.50806034 \n",
      " Prediction:  [152.10347 184.35582 180.9257  195.15001 142.73158]\n",
      "4600 Cost:  0.50631154 \n",
      " Prediction:  [152.10236 184.35628 180.92499 195.15236 142.7298 ]\n",
      "4700 Cost:  0.5045692 \n",
      " Prediction:  [152.10124 184.35677 180.92429 195.15471 142.72803]\n",
      "4800 Cost:  0.50283444 \n",
      " Prediction:  [152.10013 184.35725 180.92355 195.15703 142.72627]\n",
      "4900 Cost:  0.5010951 \n",
      " Prediction:  [152.099   184.35774 180.92284 195.15936 142.72449]\n",
      "5000 Cost:  0.4993739 \n",
      " Prediction:  [152.09787 184.35822 180.92213 195.1617  142.72272]\n"
     ]
    }
   ],
   "source": [
    "# cost가 작아질 수록 hypothesis_val가 Y_Train의 마지막 값에 가까워져야 함.\n",
    "\n",
    "# placeholder 사용 안 할 때\n",
    "# for step in range(5001):\n",
    "#     session.run(train)\n",
    "#     if step % 100 == 0:\n",
    "#         print(step, session.run(cost), session.run(W1), session.run(W2), session.run(W3), session.run(b), session.run(hypothesis))\n",
    "\n",
    "# placeholder 사용할 때\n",
    "for step in range(5001):\n",
    "    cost_val, hypothesis_val, _ = session.run([cost, hypothesis, train],\n",
    "                                              feed_dict = {x1: x1_train, x2: x2_train, x3: x3_train, y: y_train})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\n Prediction: \", hypothesis_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
